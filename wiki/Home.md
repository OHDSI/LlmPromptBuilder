# llmprompts Wiki

Welcome to the **llmprompts** project wiki! ðŸŽ‰

## Home

### Overview
**llmprompts** is a **composable**, **reusable** prompt-engineering library designed to help you build sophisticated LLM workflows by stitching together modular components. Whether you need out-of-the-box templates, system instruction roles, or advanced orchestration functions, this toolkit is built for rapid adoption and long-term maintenance.

## Why Contribute?
We believe in the power of community-driven innovation. Your ideas, bug fixes, and extensions help **llmprompts** evolve and grow. By contributing, you can:
- Enhance existing modules and templates for new use cases.
- Share domain-specific contexts and role definitions.
- Improve documentation, add examples, and guide newcomers.
- Build and maintain connectors to the latest LLM providers.

## Getting Started
1. **Clone the repo**  
   ```bash
   git clone https://github.com/Ohdsi/llmPrompts.git
   cd llmPrompts
   ```
2. **Install**  
   ```bash
   pip install .
   ```
3. **Explore and Reuse**  
   - Browse `src/llmprompts/prompts/` for ready-made templates.  
   - Check out `src/llmprompts/roles/` for persona fragments.  
   - Dive into `src/llmprompts/accelerators/` to customize orchestration.  
   - Leverage `src/llmprompts/contexts/` and `src/llmprompts/templates/` to craft unique workflows.

## How to Contribute
- Fork the repository and create a feature branch.  
- Add or improve modules under `src/llmprompts/`.  
- Write tests in `tests/` to ensure reliability.  
- Update this wiki with usage guides or tips.  
- Submit a pull request and join the discussion!

## Resources
- **Documentation:** https://github.com/Ohdsi/llmPrompts/wiki  
- **Issues:** https://github.com/Ohdsi/llmPrompts/issues  
- **Contact:** Gowtham Rao (<rao@ohdsi.org>)
